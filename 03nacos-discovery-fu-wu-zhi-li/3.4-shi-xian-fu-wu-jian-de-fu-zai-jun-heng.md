# 3.4 实现服务间的负载均衡

## 3.4.1 什么是负载均衡

通俗的讲， 负载均衡就是将负载（工作任务，访问请求）进行分摊到多个操作单元（服务器,组件）上进行执行。&#x20;

根据负载均衡发生位置的不同,一般分为**服务端负载均衡**和**客户端负载均衡**。&#x20;

服务端负载均衡指的是发生在服务提供者一方,比如常见的nginx负载均衡&#x20;

而客户端负载均衡指的是发生在服务请求的一方，也就是在发送请求之前已经选好了由哪个实例处理请求。

![](<../.gitbook/assets/image (37) (1) (1).png>)

我们在微服务调用关系中一般会选择客户端负载均衡，也就是在服务调用的一方来决定服务由哪个提供 者执行。

## 3.4.2 自定义实现负载均衡

1.通过IDEA再启动一个 ProductApplication，设置端口为8082，观察Nacos服务列表：

![](<../.gitbook/assets/image (10).png>)

![](<../.gitbook/assets/image (8) (1) (1).png>)

修改 订单服务的 controller，实现负载均衡：

```java
@RestController
@Slf4j
public class OrderController {

    @Resource
    private RestTemplate restTemplate;

    @Resource
    private OrderService orderService;

    @Resource
    private DiscoveryClient discoveryClient;

    @GetMapping("/order/prod/{pid}")
    public Order order(@PathVariable("pid") Integer pid) {
        log.info("客户下单，这时候调用商品微服务查询商品信息");;

        // 从nacos中获得服务地址
        // 自定义规则实现负载均衡
        List<ServiceInstance> instances = discoveryClient.getInstances("service-product");
        int index = new Random().nextInt(instances.size());
        ServiceInstance serviceInstance = instances.get(index);
        String url = serviceInstance.getHost() + ":" + serviceInstance.getPort();
        log.info("从nacos中获取到的微服务地址为：" + url);

        // 通过restTemplate调用
        Product product = restTemplate.getForObject(
                "http://" + url + "/product/" + pid, Product.class
        );
        if (product == null) {
            return null;
        }
        Order order = new Order();
        order.setUid(1);
        order.setUsername("Tom");
        order.setPid(product.getPid());

        // 存储数据库
        orderService.save(order);
        return order;
    }

}
```

然后重启订单服务，访问浏览器，观察控制台输出：

![](<../.gitbook/assets/image (13) (1).png>)

可以看到是无规则切换的。

## 3.4.3 基于LoadBalancer实现负载均衡

**LoadBalancer是Spring Cloud的一个组件， 它可以让我们使用一个注解就能轻松的搞定负载均衡。**

第一步，在订单服务的pom文件中加上依赖：

```markup
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-loadbalancer</artifactId>
</dependency>
```

第二步：在RestTemplate的生成方法上加上 **@LoadBalanced** 注解

```java
@SpringBootApplication
@EnableDiscoveryClient
public class OrderApplication {

    public static void main(String[] args) {
        SpringApplication.run(OrderApplication.class, args);
    }

    @Bean
    @LoadBalanced
    public RestTemplate restTemplate() {
        return new RestTemplate();
    }

}
```

第三步，修改服务调用的方法，也就是修改订单服务的controller：

```java
@RestController
@Slf4j
public class OrderController {

    @Resource
    private RestTemplate restTemplate;

    @Resource
    private OrderService orderService;

    @GetMapping("/order/prod/{pid}")
    public Order order(@PathVariable("pid") Integer pid) {
        log.info("客户下单，这时候调用商品微服务查询商品信息");

        // 直接使用微服务名字，从nacos中获取
        String url = "service-product";
        log.info("从nacos中获取到的微服务地址为：" + url);

        // 通过restTemplate调用
        Product product = restTemplate.getForObject(
                "http://" + url + "/product/" + pid, Product.class
        );
        if (product == null) {
            return null;
        }
        Order order = new Order();
        order.setUid(1);
        order.setUsername("Tom");
        order.setPid(product.getPid());

        // 存储数据库
        orderService.save(order);
        return order;
    }

}
```

访问浏览器即可。

**LoadBalancer负载均衡策略**

LoadBalancer和Ribbon支持的策略有点区别，下面是Ribbon的策略：



| 策略名                       | 策略描述                                                                                         | 实现说明                                                                                                                                                           |
| ------------------------- | -------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| BestAvailableRule         | 选择一个最小的并发请求的 server                                                                          | 逐个考察Server，如果Server被 tripped了，则忽略，在选择其中 ActiveRequestsCount最小的 server                                                                                          |
| AvailabilityFilteringRule | 过滤掉那些因为一直连接失 败的被标记为circuit tripped的后端server，并过 滤掉那些高并发的的后端 server（activeconnections 超过配置的阈值） | 使用一个AvailabilityPredicate来包 含过滤server的逻辑，其实就就是 检查status里记录的各个server的 运行状态                                                                                      |
| WeightedResponseTimeRule  | 根据相应时间分配一个 weight，相应时间越长， weight越小，被选中的可能 性越低。                                               | 一个后台线程定期的从status里面 读取评价响应时间，为每个server 计算一个weight。Weight的计算也 比较简单responsetime 减去每个 server自己平均的responsetime是 server的权重。当刚开始运行，没 有形成statas时，使用roubine策略 选择server。 |
| RetryRule                 | 对选定的负载均衡策略机上 重试机制。                                                                           | 在一个配置时间段内当选择server 不成功，则一直尝试使用subRule 的方式选择一个可用的server                                                                                                         |
| RoundRobinRule            | 轮询方式轮询选择server                                                                               | 轮询index，选择index对应位置的 server                                                                                                                                    |
| RandomRule                | 随机选择一个server                                                                                 | 在index上随机，选择index对应位 置的server                                                                                                                                  |
| ZoneAvoidanceRule         | 复合判断server所在区域的 性能和server的可用性选择 server                                                       | 使用ZoneAvoidancePredicate和 AvailabilityPredicate来判断是否选 择某个server，前一个判断判定一 个zone的运行性能是否可用，剔除 不可用的zone（的所有server）， AvailabilityPredicate用于过滤掉连 接数过多的Server。       |

Ribbon**默认是轮询策略**。

LoadBalancer只支持两种策略，分别是：**随机（RandomLoadBalancer）**和**轮询（RoundRobinLoadBalancer）**。默认都是**轮询**。

